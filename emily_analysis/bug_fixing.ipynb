{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformulated Code (error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAIDI calculation functions \n",
    "\n",
    "#first read the lookup table for identifying restore labels \n",
    "lookup = pd.read_parquet('outage_lookup.gz.parquet')\n",
    "lookup['test_time'] = lookup['time'].apply(lambda x: int(x.replace(tzinfo=timezone.utc).timestamp()))\n",
    "\n",
    "uplook = pd.DataFrame()\n",
    "for i in lookup['core_id'].unique(): \n",
    "    relevant = lookup[lookup['core_id'] == i]\n",
    "    relevant = relevant.sort_values('outage_time')\n",
    "    relevant['trans_#'] = range(len(relevant))\n",
    "    uplook = uplook.append(relevant)\n",
    "lookup = uplook\n",
    "lookup.head()\n",
    "\n",
    "\n",
    "#ignoring restore clusters \n",
    "def ignore_restore(df):\n",
    "    df['avg_out'] = df['outage_time'].apply(np.mean)\n",
    "    df['avg_restore'] = df['restore_time'].apply(np.mean)\n",
    "    df['std_out'] = df['outage_time'].apply(np.std)\n",
    "    df['std_restore'] = df['restore_time'].apply(np.std)\n",
    "    df['clust_saidi'] = (df['avg_restore'] - df['avg_out'])*df['cluster_size']\n",
    "    no_rest_SAIDI = np.sum(df['clust_saidi'])/mean(df['sensors_reporting'])\n",
    "    print(f'SAIDI when we ignore restore clustering: {no_rest_SAIDI}')\n",
    "    return df\n",
    "\n",
    "\n",
    "#this function appends the label of the restore cluster to the sensor in an outage cluster (does not deal with inverse noise)\n",
    "def restore_clusters_exploded(db_out, db_restore, lookup, out_or_restore, other):   \n",
    "    r_times = pd.DataFrame(db_restore.explode(other)[other])\n",
    "    r_ids = pd.DataFrame(db_restore.explode('ids')['ids'])\n",
    "    o_times = pd.DataFrame(db_out.explode(out_or_restore)[out_or_restore])\n",
    "    o_ids = pd.DataFrame(db_out.explode('ids')['ids'])\n",
    "    restore = r_times.combine_first(r_ids).reset_index()\n",
    "    out = o_times.combine_first(o_ids).reset_index()\n",
    "    restore_labels = []\n",
    "    lat = []\n",
    "    long = []\n",
    "    multi = 0 \n",
    "    for i in range(len(out)):\n",
    "        time, eyed = out.iloc[i][out_or_restore], out.iloc[i]['ids']\n",
    "        lookedup = lookup[(lookup[out_or_restore] == time) & (lookup['core_id'] == eyed) & (lookup['is_powered'] == False)]\n",
    "        lat.append(lookedup['location_latitude'].values[0])\n",
    "        long.append(lookedup['location_longitude'].values[0])\n",
    "        if len(lookedup) == 1: \n",
    "            rest_time = lookedup[other].values[0]\n",
    "            row = restore[(restore[other] == rest_time) & (restore['ids'] == eyed)]\n",
    "            if len(row) == 1:\n",
    "                restore_labels.append(row['labels'].values[0])\n",
    "            else: \n",
    "                restore_labels.append(-1)\n",
    "        elif len(lookedup) > 1: \n",
    "            multi += 1 \n",
    "            rest_time = lookedup[other].values[0]\n",
    "            row = restore[(restore[other] == rest_time) & (restore['ids'] == eyed)]\n",
    "            if len(row) == 1:\n",
    "                restore_labels.append(row['labels'].values[0])\n",
    "            else: \n",
    "                restore_labels.append(-1)\n",
    "        else: \n",
    "            print('problem: outage time not in the lookup table')\n",
    "    out[other] = db_out.explode(other)[other].values\n",
    "    out['restore_labels'] = restore_labels\n",
    "    out['latitude'] = lat \n",
    "    out['longitude'] = long\n",
    "    out['sensors_reporting'] = db_out.explode(out_or_restore)['sensors_reporting'].values\n",
    "    return out\n",
    "\n",
    "\n",
    "def db_w_labels(df, o_r_labels, other):\n",
    "    percentage = []\n",
    "    noise = []\n",
    "    out_size = []\n",
    "    for i in df[other].unique(): \n",
    "        a_df = df[df[other] == i]\n",
    "        per = [len(a_df[o_r_labels].unique())]*len(a_df)\n",
    "        n = [(len(a_df[a_df[o_r_labels] == -1]))/(len(a_df))]*len(a_df)\n",
    "        o = [len(a_df)]*len(a_df)\n",
    "        percentage.append(per)\n",
    "        noise.append(n)\n",
    "        out_size.append(o)\n",
    "    percentage = [item for sublist in percentage for item in sublist]\n",
    "    noise = [item for sublist in noise for item in sublist]\n",
    "    out_size = [item for sublist in out_size for item in sublist]\n",
    "    df['restore_groups'] = percentage \n",
    "    df['%_noise'] = noise\n",
    "    df['out_size'] = out_size\n",
    "    rest_count = pd.DataFrame(df.groupby(o_r_labels).count()[other])\n",
    "    if other == 'labels':\n",
    "        df = df.join(rest_count, on=o_r_labels, rsuffix='_').rename(columns={'labels_' : 'rest_size'})\n",
    "        avg_restore_time = pd.DataFrame(df.groupby('restore_labels')['restore_time'].apply(np.mean))\n",
    "        df = df.join(avg_restore_time, on='restore_labels', rsuffix='_').rename(columns={'restore_time_' : 'avg_rest_time'})\n",
    "    if other == 'restore_labels':\n",
    "        df = df.join(rest_count, on=other, rsuffix='_').rename(columns={'restore_labels_' : 'out_size'})\n",
    "        avg_restore_time = pd.DataFrame(df.groupby('out_labels')['outage_time'].apply(np.mean))\n",
    "        df = df.join(avg_restore_time, on='labels', rsuffix='_').rename(columns={'outage_time_' : 'avg_out_time'})\n",
    "    return df\n",
    "\n",
    "\n",
    "def avg_time_std_dur(df, out):\n",
    "    mean_outage = out.groupby('labels')['outage_time'].apply(mean)\n",
    "    mean_restore = out.groupby('labels')['restore_time'].apply(mean)\n",
    "    std_outage = out.groupby('labels')['outage_time'].apply(np.std)\n",
    "    std_restore = out.groupby('labels')['restore_time'].apply(np.std)\n",
    "    num_sens = df.groupby('labels').count()['ids']\n",
    "    \n",
    "    df = df.join(mean_outage, on='labels', rsuffix='_').rename(columns={'outage_time_': 'mean_outage_time'})\n",
    "    df = df.join(mean_restore, on='labels', rsuffix='_').rename(columns={'restore_time_': 'mean_restore_time'})\n",
    "    df = df.join(std_outage, on='labels', rsuffix='__').rename(columns={'outage_time__': 'outage_time_stdev'})\n",
    "    df = df.join(std_restore, on='labels', rsuffix='__').rename(columns={'restore_time__': 'restore_time_stdev'})\n",
    "    df = df.join(num_sens, on='labels', rsuffix='__').rename(columns={'ids__': 'num_sens_out'})\n",
    "    df['clust_saidi'] = (df['mean_restore_time'] - df['mean_outage_time'])*df['num_sens_out']\n",
    "    return df \n",
    "\n",
    "\n",
    "def n_noise_saidi(df, out):\n",
    "    no_noise_duration = avg_time_std_dur(df[df['restore_labels'] != -1], out)\n",
    "    noise_duration = avg_time_std_dur(df[df['restore_labels'] == -1], out)\n",
    "    no_noise_SAIDI = np.sum(no_noise_duration.groupby('labels').mean()['clust_saidi'])/ np.mean(no_noise_duration.groupby('labels').mean()['sensors_reporting'])\n",
    "    noise_SAIDI = np.sum(noise_duration.groupby('labels').mean()['clust_saidi'])/ np.mean(noise_duration.groupby('labels').mean()['sensors_reporting'])\n",
    "    print(f'SAIDI when we eliminate all noise: {noise_SAIDI}')\n",
    "    print(f'SAIDI when we only include noise points: {no_noise_SAIDI}')\n",
    "    return df\n",
    "\n",
    "\n",
    "#noise clustered with nearest time \n",
    "def closest_time(df, avg_time, r_o_time):\n",
    "    noise = df[df['restore_labels'] == -1]\n",
    "    no_noise = df[df['restore_labels'] != -1]\n",
    "    nearest = []\n",
    "    for i in noise[r_o_time].values:\n",
    "        nearest_label = pd.DataFrame(abs(avg_restore_time[r_o_time] - i)).sort_values(r_o_time).index[0]\n",
    "        nearest.append(nearest_label)\n",
    "    noise['nearest_time_labels'] = nearest\n",
    "    noise = pd.DataFrame(noise['nearest_time_labels'])\n",
    "    updated_df = df.join(noise)\n",
    "    updated_df['restore_labels'] = updated_df['nearest_time_labels'].combine_first(df['restore_labels'])\n",
    "    avg_restore_times = pd.DataFrame(updated_df.groupby('restore_labels')[r_o_time].apply(np.mean))\n",
    "    if r_o_time == 'restore_time':\n",
    "        closest_time_noise = updated_df.join(avg_time, on='restore_labels', rsuffix='_').rename(columns={'restore_time_' : 'avg_rest_times'})\n",
    "    else: \n",
    "        closest_time_noise = updated_df.join(avg_time, on='restore_labels', rsuffix='_').rename(columns={'outage_time_' : 'avg_out_times'})        \n",
    "    closest_time_noise = avg_time_std_dur_noise(closest_time_noise, 'time')\n",
    "    return closest_time_noise\n",
    "\n",
    "\n",
    "def avg_time_std_dur_noise(df, wrt):\n",
    "    mean_outage = df.groupby('labels')['outage_time'].apply(mean)\n",
    "    mean_restore = df.groupby('labels')['avg_rest_times'].apply(mean)\n",
    "    std_outage = df.groupby('labels')['outage_time'].apply(np.std)\n",
    "    std_restore = df.groupby('labels')['avg_rest_times'].apply(np.std)\n",
    "    \n",
    "    df = df.join(mean_outage, on='labels', rsuffix='_').rename(columns={'outage_time_': 'mean_outage_time'})\n",
    "    df = df.join(mean_restore, on='labels', rsuffix='_').rename(columns={'avg_rest_times_': 'mean_restore_time'})\n",
    "    df = df.join(std_outage, on='labels', rsuffix='__').rename(columns={'outage_time__': 'outage_time_stdev'})\n",
    "    df = df.join(std_restore, on='labels', rsuffix='__').rename(columns={'avg_rest_times__': 'restore_time_stdev'})\n",
    "    df['clust_saidi'] = (df['mean_restore_time'] - df['mean_outage_time'])*df['out_size']\n",
    "    time_noise_SAIDI = np.sum(df.groupby('labels').mean()['clust_saidi'])/ np.mean(df.groupby('labels').mean()['sensors_reporting'])\n",
    "    print(f'SAIDI when noise restores are clustered with the nearest restore with respect to {wrt}: {time_noise_SAIDI}')\n",
    "    return df \n",
    "\n",
    "\n",
    "#noise clustered with nearest distance in space \n",
    "\n",
    "def closest_dist(df):\n",
    "    noise = df[df['restore_labels'] == -1]\n",
    "    no_noise = df[df['restore_labels'] != -1]\n",
    "    nearest = []\n",
    "    for n in range(len(noise)):\n",
    "        lat = noise.iloc[n]['latitude']\n",
    "        long = noise.iloc[n]['longitude']\n",
    "        a_time = noise.iloc[n]['restore_time']\n",
    "        calc_dist = pd.DataFrame(np.sqrt((no_noise['latitude'] - lat)**2 + (no_noise['longitude'] - long)**2)) \n",
    "        calc_dist['restore_labels'] = no_noise['restore_labels']\n",
    "        nearest_labels = calc_dist[calc_dist[0] == calc_dist.sort_values(0).iloc[0][0]]['restore_labels'].values\n",
    "        if len(nearest_labels) ==1:\n",
    "            nearest_label = nearest_labels[0]\n",
    "        else: \n",
    "            nearest_dist_times = avg_restore_time[avg_restore_time.index.isin(nearest_labels)]\n",
    "            nearest_label = pd.DataFrame(abs(nearest_dist_times['restore_time'] - a_time)).sort_values('restore_time').index[0]\n",
    "        nearest.append(nearest_label)\n",
    "    noise['nearest_dist_labels'] = nearest\n",
    "    noise = pd.DataFrame(noise['nearest_dist_labels'])\n",
    "    updated_df = df.join(noise)\n",
    "    updated_df['restore_labels'] = updated_df['nearest_dist_labels'].combine_first(df['restore_labels'])\n",
    "    avg_restore_times = pd.DataFrame(updated_df.groupby('restore_labels')['restore_time'].apply(np.mean))\n",
    "    updated_df = updated_df.join(avg_restore_times, on='restore_labels', rsuffix='_').rename(columns={'restore_time_' : 'avg_rest_times'})\n",
    "    updated_df = avg_time_std_dur_noise(updated_df, 'space and time')\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_db(time_label):\n",
    "    data = two_days\n",
    "    clustered_outages = run_dbscan(data, time_label)\n",
    "    dbscan_formatted_clusters = prep_cluster_data(clustered_outages, time_label)\n",
    "    dbscan_outages = run_convex_hull(dbscan_formatted_clusters, time_label)\n",
    "    return dbscan_outages\n",
    "    \n",
    "db_out = cluster_db('outage_time')\n",
    "db_restore = cluster_db('restore_time')\n",
    "ignore_restore_clust = ignore_restore(db_out)\n",
    "db_out_clusters = restore_clusters_exploded(db_out, db_restore, lookup, 'outage_time', 'restore_time')\n",
    "db_out_clusters = db_w_labels(db_out_clusters, 'restore_labels', 'labels')\n",
    "n_noise = n_noise_saidi(db_out_clusters, db_out_clusters)\n",
    "avg_restore_time = pd.DataFrame(db_out_clusters[db_out_clusters['restore_labels'] != -1].groupby('restore_labels')['restore_time'].apply(np.mean))\n",
    "db_nearest_time = closest_time(db_out_clusters, avg_restore_time, 'restore_time')\n",
    "closest_dist_noise = closest_dist(db_out_clusters)\n",
    "closest_dist_noise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run SAIDI algorithm on restore clusters \n",
    "\n",
    "ignore_out_clust = ignore_restore(db_restore)\n",
    "db_rest_clusters = restore_clusters_exploded(db_restore, db_out, lookup, 'restore_time', 'outage_time')\n",
    "db_rest_clusters = n_noise_saidi(db_rest_clusters, db_rest_clusters)\n",
    "avg_outage_time = pd.DataFrame(db_rest_clusters[db_rest_clusters['restore_labels'] != -1].groupby('restore_labels')['outage_time'].apply(np.mean))\n",
    "db_nearest_time = closest_time(db_rest_clusters, avg_outage_time, 'outage_time')\n",
    "# closest_dist_noise = closest_dist(db_rest_clusters)\n",
    "# closest_dist_noise\n",
    "#this gives an error for closest_time because when we call closest time on the restore clusters, we rename \"avg_out_times\"\n",
    "#this throws and error when then we use avg_time_std_dur_noise, which requires the column to be called \"avg_rest_times\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this are the OG functions closest_time and closest_dist \n",
    "\n",
    "# def closest_time(df):\n",
    "#     noise = df[df['restore_labels'] == -1]\n",
    "#     nearest = []\n",
    "#     for i in noise['restore_time'].values:\n",
    "#         nearest_label = pd.DataFrame(abs(avg_restore_time['restore_time'] - i)).sort_values('restore_time').index[0]\n",
    "#         nearest.append(nearest_label)\n",
    "#     noise['nearest_time_labels'] = nearest\n",
    "#     noise = pd.DataFrame(noise['nearest_time_labels'])\n",
    "#     updated_df = df.join(noise)\n",
    "#     updated_df['restore_labels'] = updated_df['nearest_time_labels'].combine_first(df['restore_labels'])\n",
    "\n",
    "#     return updated_df\n",
    "\n",
    "# closest_time_noise = closest_time(db_out_clusters)\n",
    "# avg_restore_times = pd.DataFrame(closest_time_noise.groupby('restore_labels')['restore_time'].apply(np.mean))\n",
    "# closest_time_noise = closest_time_noise.join(avg_restore_times, on='restore_labels', rsuffix='_').rename(columns={'restore_time_' : 'avg_rest_times'})\n",
    "# closest_time_noise\n",
    "\n",
    "def avg_time_std_dur_noise(df):\n",
    "    mean_outage = df.groupby('labels')['outage_time'].apply(mean)\n",
    "    mean_restore = df.groupby('labels')['avg_rest_times'].apply(mean)\n",
    "    std_outage = df.groupby('labels')['outage_time'].apply(np.std)\n",
    "    std_restore = df.groupby('labels')['avg_rest_times'].apply(np.std)\n",
    "    \n",
    "    df = df.join(mean_outage, on='labels', rsuffix='_').rename(columns={'outage_time_': 'mean_outage_time'})\n",
    "    df = df.join(mean_restore, on='labels', rsuffix='_').rename(columns={'avg_rest_times_': 'mean_restore_time'})\n",
    "    df = df.join(std_outage, on='labels', rsuffix='__').rename(columns={'outage_time__': 'outage_time_stdev'})\n",
    "    df = df.join(std_restore, on='labels', rsuffix='__').rename(columns={'avg_rest_times__': 'restore_time_stdev'})\n",
    "    df['clust_saidi'] = (df['mean_restore_time'] - df['mean_outage_time'])*df['out_size']\n",
    "    return df \n",
    "\n",
    "time_noise_duration = avg_time_std_dur_noise(closest_time_noise)\n",
    "time_noise_SAIDI = np.sum(time_noise_duration.groupby('labels').mean()['clust_saidi'])/ np.mean(time_noise_duration.groupby('labels').mean()['sensors_reporting'])\n",
    "time_noise_SAIDI\n",
    "\n",
    "def closest_dist(df):\n",
    "    noise = df[df['restore_labels'] == -1]\n",
    "    nearest = []\n",
    "    for n in range(len(noise)):\n",
    "        lat = noise.iloc[n]['latitude']\n",
    "        long = noise.iloc[n]['longitude']\n",
    "        a_time = noise.iloc[n]['restore_time']\n",
    "        calc_dist = pd.DataFrame(np.sqrt((df['latitude'] - lat)**2 + (df['longitude'] - long)**2)) \n",
    "        calc_dist['labels'] = db_out_clusters['labels']\n",
    "        nearest_labels = calc_dist[calc_dist[0] == calc_dist.sort_values(0)[0].values]['labels']        \n",
    "        nearest_dist_times = avg_restore_time[avg_restore_time.index.isin(nearest_labels)]\n",
    "        nearest_label = pd.DataFrame(abs(nearest_dist_times['restore_time'] - a_time)).sort_values('restore_time').index[0]\n",
    "        nearest.append(nearest_label)\n",
    "    noise['nearest_dist_labels'] = nearest\n",
    "    noise = pd.DataFrame(noise['nearest_dist_labels'])\n",
    "    updated_df = df.join(noise)\n",
    "    updated_df['restore_labels'] = updated_df['nearest_dist_labels'].combine_first(df['restore_labels'])\n",
    "\n",
    "    return updated_df\n",
    "\n",
    "closest_dist_noise = closest_dist(db_out_clusters)\n",
    "avg_restore_times = pd.DataFrame(closest_dist_noise.groupby('restore_labels')['restore_time'].apply(np.mean))\n",
    "closest_dist_noise = closest_dist_noise.join(avg_restore_times, on='restore_labels', rsuffix='_').rename(columns={'restore_time_' : 'avg_rest_times'})\n",
    "closest_dist_noise\n",
    "\n",
    "\n",
    "\n",
    "dist_noise_duration = avg_time_std_dur_noise(closest_dist_noise)\n",
    "dist_noise_SAIDI = np.sum(dist_noise_duration.groupby('labels').mean()['clust_saidi'])/ np.mean(time_noise_duration.groupby('labels').mean()['sensors_reporting'])\n",
    "dist_noise_SAIDI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}